# Cantonese Speech-to-Text Web Application

A professional web application for Cantonese speech-to-text transcription with AI-powered speaker identification and interactive audio playback.

## Features

### ğŸ¯ Core Functionality
- **Cantonese Speech Recognition** - High-quality transcription using ElevenLabs AI
- **Speaker Diarization** - Automatic speaker separation and identification
- **AI Speaker Identification** - Match speakers to participant names using DeepSeek R1
- **Interactive Audio Player** - Click on text to jump to specific audio timestamps
- **Chinese Character Conversion** - Automatic simplified to traditional Chinese conversion

### ğŸ›¡ï¸ Production Ready
- **Rate Limiting** - 10 requests per 24 hours per user
- **Audio Duration Limits** - Maximum 10 minutes, 50MB file size
- **Secure Backend** - API keys managed server-side
- **Error Handling** - Comprehensive error messages and validation

### ğŸ¬ Demo Available
Try the live demo with a sample from **è§€å¡˜å€è­°æœƒç¬¬ä¸ƒæ¬¡æœƒè­°** (Kwun Tong District Council meeting):
- **Audio Source**: Official Hong Kong District Council meeting proceedings
- **Content**: "å…¶ä»–äº‹é …" (Other Matters) agenda item (4:38 duration)
- **Participants**: 46+ council members and government officials
- **Language**: Cantonese with traditional Chinese output

## Quick Start

### 1. Environment Setup
```bash
# Clone the repository
git clone <your-repo-url>
cd speech-to-text

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env.local
# Add your FAL_AI_API_KEY to .env.local
```

### 2. Get API Key
1. Sign up at [fal.ai](https://fal.ai)
2. Get your API key from the dashboard
3. Add to `.env.local`:
   ```
   FAL_AI_API_KEY=your_actual_api_key_here
   ```

### 3. Run Development
```bash
npm run dev
# Open http://localhost:3000
```

### 4. Deploy to Vercel
1. Push to GitHub
2. Import to Vercel
3. Add `FAL_AI_API_KEY` to Vercel environment variables
4. Deploy!

## Usage

### Option 1: Try Demo
1. Click **"ğŸ¬ Try Demo"** button
2. Watch automatic transcription of council meeting audio
3. See AI speaker identification in action

### Option 2: Upload Your Own Audio
1. Upload audio file (MP3, WAV, M4A supported)
2. Select language (Cantonese recommended)
3. Optionally enable speaker identification
4. View results with interactive audio player

## Technical Architecture

### Backend API Routes
- `/api/transcribe` - Speech-to-text processing with fal.ai/elevenlabs
- `/api/speaker-identify` - AI speaker identification with DeepSeek R1

### Rate Limiting & Security
- IP-based rate limiting (24-hour windows)
- Server-side API key management
- Audio validation and size limits
- Comprehensive error handling

### Tech Stack
- **Frontend**: Next.js 14, React, TypeScript, TailwindCSS
- **Backend**: Next.js API Routes, Vercel Serverless Functions
- **AI Services**: fal.ai (ElevenLabs speech-to-text, DeepSeek R1)
- **Deployment**: Vercel

## Demo Content Attribution

The demo audio is sourced from official Hong Kong District Council proceedings:

- **Meeting**: è§€å¡˜å€è­°æœƒç¬¬ä¸ƒæ¬¡æœƒè­° (Kwun Tong District Council 7th Meeting)
- **Date**: 2025-01-06
- **Agenda**: å…¶ä»–äº‹é … (Other Matters) - 4:38 duration
- **Source**: [Hong Kong District Councils](https://www.districtcouncils.gov.hk/kt/tc_chi/meetings/dcmeetings/dc_meetings_audio.php?meeting_id=28585)
- **Copyright**: Â© Hong Kong District Councils (Used under fair use for demonstration)

## Development

### Project Structure
```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # Backend API routes
â”‚   â”‚   â”œâ”€â”€ lib/          # Shared utilities
â”‚   â”‚   â”œâ”€â”€ transcribe/   # Speech-to-text endpoint
â”‚   â”‚   â””â”€â”€ speaker-identify/ # Speaker ID endpoint
â”‚   â”œâ”€â”€ globals.css       # Global styles
â”‚   â”œâ”€â”€ layout.tsx        # App layout
â”‚   â””â”€â”€ page.tsx          # Main app component
â”œâ”€â”€ public/               # Static files
â”‚   â”œâ”€â”€ demo-audio.mp3    # Demo audio file
â”‚   â””â”€â”€ demo-participants.txt # Demo participant list
â””â”€â”€ tests/                # Test files and examples
```

### Key Features Implementation
- **Rate Limiting**: In-memory store with IP tracking
- **Audio Validation**: Client and server-side duration/size checks
- **Speaker ID**: DeepSeek R1 AI with conversation pattern analysis
- **Chinese Conversion**: Simplified to Traditional character conversion
- **Interactive Player**: Audio synchronization with transcript text

## License

MIT License - See LICENSE file for details.

## Contributing

1. Fork the repository
2. Create feature branch
3. Make changes with proper attribution
4. Submit pull request

For demo content, ensure proper attribution to original sources. 